# ğŸ›°ï¸ Proyecto de DetecciÃ³n Geoespacial de Frailejones  
**Inferencia distribuida con PySpark + YOLOv5 + Spark YARN**

Este proyecto permite detectar frailejones en imÃ¡genes satelitales (mosaicos `.tif`), divididas en tiles, usando modelos de visiÃ³n por computador (YOLOv5 o RTDETR), de forma distribuida usando PySpark, tanto localmente como en un clÃºster Hadoop.

---

## ğŸ“ Estructura del Proyecto

ADGE_GH_FINAL/
â”œâ”€â”€ datasets/
â”‚ â””â”€â”€ 19_dic_2024_bajito_mask_test/
â”‚ â”œâ”€â”€ dataset/images/test/ # Tiles PNG (512x512)
â”‚ â””â”€â”€ tile_metadata.json # Metadatos geoespaciales
â”œâ”€â”€ spark_env/ # Entorno virtual con dependencias instaladas
â”œâ”€â”€ spark_env.tar.gz # Entorno comprimido para usar con YARN
â”œâ”€â”€ distributed_geospatial_detection/ 
â”‚   â””â”€â”€ original_scripts # CÃ³digo base original
â”‚   â””â”€â”€ spark_scripts/
â”‚       â”œâ”€â”€ data/
â”‚       â”‚ â”œâ”€â”€ input_images.txt # Lista de tiles a procesar
â”‚       â”‚ â””â”€â”€ generate_input_images_txt.py # Script que genera input_images.txt
â”‚       â”œâ”€â”€ models/
â”‚       â”‚ â””â”€â”€ yolo_best_fine_tune_800.pt # Pesos del modelo YOLOv5
â”‚       â”œâ”€â”€ spark_job/
â”‚       â”‚ â”œâ”€â”€ distributed_inference.py # Script principal de inferencia
â”‚       â”‚ â””â”€â”€ utils.py # Funciones auxiliares
â”‚       â”œâ”€â”€ run_local.sh # EjecuciÃ³n local
â”‚       â””â”€â”€ run_yarn.sh # EjecuciÃ³n en Hadoop YARN
â”‚    â””â”€â”€ requirements.txt # Requisitos Python (excepto GDAL)
|    â””â”€â”€ README.md


---

## âš™ï¸ InstalaciÃ³n del entorno virtual


# 1. Crear y activar entorno virtual
```bash
python3 -m venv spark_env
source spark_env/bin/activate
```

# 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

# 3. Comprimir el entorno para usar con Spark YARN
```bash
deactivate
tar -czf spark_env.tar.gz spark_env
```

ğŸ§¾ Generar lista de imÃ¡genes a procesar
```bash
python spark_scripts/data/generate_input_images_txt.py
```

ğŸš€ Ejecutar el proyecto
ğŸ”¹ OpciÃ³n 1: Local (pruebas en PC)
```bash
bash spark_scripts/run_local.sh
```

Esto ejecuta el proceso en paralelo en tu mÃ¡quina local usando todos los nÃºcleos disponibles.

ğŸ”¹ OpciÃ³n 2: En clÃºster Hadoop (YARN)
```bash
bash spark_scripts/run_yarn.sh
```

Esto ejecuta el proceso en modo distribuido entre los nodos del clÃºster usando YARN y el entorno empaquetado.

ğŸ“¦ Salida esperada
Se generarÃ¡ una carpeta tipo:

```bash
spark_scripts/data/predictions.csv/
â”œâ”€â”€ part-00000...
```